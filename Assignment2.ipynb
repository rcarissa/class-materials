{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcarissa/class-materials/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo9dlmjDauXK"
      },
      "source": [
        "## Map Reduce Practices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZvQyCwauXP"
      },
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from functools import partial, reduce\n",
        "from itertools import groupby\n",
        "from multiprocessing import Pool, Process\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import helper"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyF_virkauXR"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8PMyXg5auXR"
      },
      "source": [
        "data_folder = Path('Volumes/GoogleDrive/MyDrive/AirlineInfo')\n",
        "data_files = sorted(data_folder.glob('*.csv.bz2'))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEuLedMYc4S_",
        "outputId": "8edcdf14-6763-4bb0-c99e-80a8f174bb57"
      },
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBszq1fHe4WJ"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "data_folder = Path('/content/drive/MyDrive/AirlineInfo')\n",
        "data_files = sorted(data_folder.glob('*.csv.bz2'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEXE-gM941j0"
      },
      "source": [
        "AIRLINE_DTYPES = {\n",
        "    'Year': 'int64',\n",
        "    'Month': 'int64',\n",
        "    'DayofMonth': 'int64',\n",
        "    'DayOfWeek': 'int64',\n",
        "    'DepTime': 'float64',\n",
        "    'CRSDepTime': 'float64',\n",
        "    'ArrTime': 'float64',\n",
        "    'CRSArrTime': 'float64',\n",
        "    'UniqueCarrier': 'string',\n",
        "    'FlightNum': 'float64',\n",
        "    'TailNum': 'string',\n",
        "    'ActualElapsedTime': 'float64',\n",
        "    'CRSElapsedTime': 'float64',\n",
        "    'AirTime': 'float64',\n",
        "    'ArrDelay': 'float64',\n",
        "    'DepDelay': 'float64',\n",
        "    'Origin': 'string',\n",
        "    'Dest': 'string',\n",
        "    'Distance': 'float64',\n",
        "    'TaxiIn': 'float64',\n",
        "    'TaxiOut': 'float64',\n",
        "    'Cancelled': 'int64',\n",
        "    'CancellationCode': 'string',\n",
        "    'Diverted': 'int64',\n",
        "    'CarrierDelay': 'float64',\n",
        "    'WeatherDelay': 'float64',\n",
        "    'NASDelay': 'float64',\n",
        "    'SecurityDelay': 'float64',\n",
        "    'LateAircraftDelay': 'float64',\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwnqjTq8PmUO"
      },
      "source": [
        "def read_airline_files(data_files, num_of_files=22, processing='single') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Read all files into one single dataframe.\n",
        "    Notes:\n",
        "    This function will work only if you have a large amount of RAM\n",
        "    on your computer. For example, anything above 30 GB should work.\n",
        "    If you have less RAM, you can limit the number of files to load\n",
        "    with this function with the parameter. First 8 files consumes \n",
        "    13 GB memory space.\n",
        "    For more information on this issue, check out the stackoverflow\n",
        "    answer: https://datascience.stackexchange.com/a/27794/61094.\n",
        "    Another nice answer on this issue is the following:\n",
        "    https://stackoverflow.com/a/60616527/5159551\n",
        "    Parameters:\n",
        "    data_files:\n",
        "        List of data files \n",
        "    num_of_files:\n",
        "        How many files from the data folder you want to\n",
        "        load to. Range is (0, 22].\n",
        "    processing:\n",
        "        Defines if multiprocessing is used while reading\n",
        "        files. Use `single` for serial, `multi` for \n",
        "        multiprocessing, and `thread` for multithreading.\n",
        "    Use following to see actual memory usage the returned \n",
        "    dataframe.\n",
        "    >>> df.info(verbose=False, memory_usage=\"deep\")\n",
        "    \"\"\"\n",
        "    if num_of_files not in range(1, 23):\n",
        "        raise ValueError('Incorrect number of files.')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYRsPWv1P78U"
      },
      "source": [
        "# partial function\n",
        "par_func = partial(\n",
        "    pd.read_csv,\n",
        "    compression='bz2',\n",
        "    encoding='ISO-8859-1',\n",
        "    engine='c',\n",
        "    low_memory=False,\n",
        "    dtype=AIRLINE_DTYPES,\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "wq0wcVMeQAvw",
        "outputId": "95d5a14e-5e7d-49d8-a153-940015c7842e"
      },
      "source": [
        "# run partial function for all file paths and concat the dataframe\n",
        "if processing == 'single':\n",
        "    df = pd.concat(\n",
        "        map(par_func, data_files[:num_of_files]), ignore_index=True)\n",
        "elif processing == 'multi':\n",
        "    with Pool() as pool:\n",
        "        df_list = pool.map(par_func, data_files[:num_of_files])\n",
        "        df = pd.concat(df_list, ignore_index=True)\n",
        "        del df_list\n",
        "elif processing == 'thread':\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        df_list = executor.map(par_func, data_files[:num_of_files])\n",
        "        df = pd.concat(df_list, ignore_index=True)\n",
        "        del df_list\n",
        "else:\n",
        "    raise ValueError('Incorrect value for processing.')\n",
        "\n",
        "return df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4bfd776660a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run partial function for all file paths and concat the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mprocessing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     df = pd.concat(\n\u001b[1;32m      4\u001b[0m         map(par_func, data_files[:num_of_files]), ignore_index=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mprocessing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'processing' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Try3HAY1QOkR"
      },
      "source": [
        "def read_airline_file(data_file, **read_csv_kwargs) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Read a single file into dataframe.\n",
        "    \"\"\"\n",
        "    return pd.read_csv(\n",
        "        filepath_or_buffer=data_file,\n",
        "        compression='bz2',\n",
        "        encoding='ISO-8859-1',\n",
        "        engine='c',\n",
        "        low_memory=False,\n",
        "        dtype=AIRLINE_DTYPES,\n",
        "        **read_csv_kwargs\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9FF2CYdQRYR"
      },
      "source": [
        "def read_csv_with_multiprocessing(files, pool_kwargs) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Read multiple CSV files into a single dataframe\n",
        "    with multiprocessing.\n",
        "    \"\"\"\n",
        "    with Pool(**pool_kwargs) as pool:\n",
        "        df_list = pool.map(pd.read_csv, files)\n",
        "        combined_df = pd.concat(df_list, ignore_index=True)\n",
        "    return combined_df"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ofCDP76auXT"
      },
      "source": [
        "### Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlKE8EOyauXT"
      },
      "source": [
        "Find the # of flights each airline made so far  from 1987 until recent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn2GB9-nauXT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsiCXDbiauXU"
      },
      "source": [
        "Find the mean departure delay per origination airport."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6kus02kauXU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlhlyjfGauXU"
      },
      "source": [
        "What is the average departure delay from each airport?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHmZ5sXdauXU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXUDV-9-auXU"
      },
      "source": [
        "What day the delays are the worst?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M18xukf8auXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzjeG75FauXV"
      },
      "source": [
        "Which day of the week is the most of the flights cancelled?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9EJpvmaauXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcxP9t9aauXV"
      },
      "source": [
        "Which day of the month is the most of the flights cancelled?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euqxUfc4auXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H83lDB9RauXV"
      },
      "source": [
        "Find the on-time (`ArrTime - CRSArrTime <= 0`) performance for each unique carrier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDvua05uauXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}